{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T17:35:05.520266Z",
     "start_time": "2022-03-01T17:35:05.505275Z"
    }
   },
   "source": [
    "## Neural Networks Assignment- Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T17:33:34.674419Z",
     "start_time": "2022-03-01T17:33:34.661427Z"
    }
   },
   "source": [
    "#### Q. PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-01T18:56:54.591Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:56:29.171251Z",
     "start_time": "2022-03-01T18:56:11.984526Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:56:32.572873Z",
     "start_time": "2022-03-01T18:56:32.476933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "data = pd.read_csv('forestfires.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:56:35.504790Z",
     "start_time": "2022-03-01T18:56:35.389860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Describing the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:35:26.702790Z",
     "start_time": "2022-03-01T18:35:12.878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'day', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind',\n",
       "       'rain', 'area', 'dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n",
       "       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n",
       "       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov',\n",
       "       'monthoct', 'monthsep', 'size_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:35:26.707786Z",
     "start_time": "2022-03-01T18:35:12.884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517, 31)\n"
     ]
    }
   ],
   "source": [
    "#data dimentions\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Infoormation about the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:40:54.630167Z",
     "start_time": "2022-03-01T18:40:54.555214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FFMC   DMC     DC  ISI  temp  RH  wind  rain  area  dayfri  ...  monthdec  \\\n",
       "0  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0       1  ...         0   \n",
       "1  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0       0  ...         0   \n",
       "2  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0       0  ...         0   \n",
       "3  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0       1  ...         0   \n",
       "4  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0       0  ...         0   \n",
       "\n",
       "   monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0         0         0         0         0         1         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         1         0         0   \n",
       "4         0         0         0         0         1         0         0   \n",
       "\n",
       "   monthoct  monthsep  \n",
       "0         0         0  \n",
       "1         1         0  \n",
       "2         1         0  \n",
       "3         0         0  \n",
       "4         0         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the data\n",
    "X = data.iloc[:,2:30]\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  size_category\n",
       "0         small\n",
       "1         small\n",
       "2         small\n",
       "3         small\n",
       "4         small"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[:,-1:]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc= StandardScaler()\n",
    "data_uni = sc.fit_transform(X)\n",
    "data_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the PCA method to extract the most useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02, -1.63123746e-15, -1.82952040e-15],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02, -1.84709097e-15, -2.24485215e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02, -1.14677888e-16,  6.72764002e-16],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -8.04607326e-16,  9.20686618e-17],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -9.63587139e-17,  9.54746883e-17],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  1.02062130e-16,  1.37345570e-17]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca= PCA(n_components = 28)\n",
    "pca_values = pca.fit_transform(data_uni)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 4.57046932e-33])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Varience\n",
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_1 = np.cumsum(np.round(var,decimals=4)*100)\n",
    "var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c0075ef550>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the varience\n",
    "plt.plot(var_1,color= 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T19:41:49.689067Z",
     "start_time": "2022-03-04T19:41:49.312594Z"
    }
   },
   "source": [
    "### From the above plot we have considered that 20 PCA features are good enought to build the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc12</th>\n",
       "      <th>pc13</th>\n",
       "      <th>pc14</th>\n",
       "      <th>pc15</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>1.234550</td>\n",
       "      <td>0.276198</td>\n",
       "      <td>-0.671216</td>\n",
       "      <td>-0.529599</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.568255</td>\n",
       "      <td>2.095225</td>\n",
       "      <td>1.417634</td>\n",
       "      <td>-0.879983</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601439</td>\n",
       "      <td>1.998004</td>\n",
       "      <td>1.477351</td>\n",
       "      <td>-0.946682</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019492</td>\n",
       "      <td>0.576990</td>\n",
       "      <td>-0.752744</td>\n",
       "      <td>0.349346</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>1.131879</td>\n",
       "      <td>-0.137990</td>\n",
       "      <td>-0.823316</td>\n",
       "      <td>0.402298</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0  3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1  0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2  0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3  3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4  2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "\n",
       "        pc8       pc9      pc10  ...      pc12      pc13      pc14      pc15  \\\n",
       "0 -0.019764  0.010161 -0.437314  ...  1.234550  0.276198 -0.671216 -0.529599   \n",
       "1  0.041095 -0.548879  0.104500  ... -0.568255  2.095225  1.417634 -0.879983   \n",
       "2 -2.159336 -0.090580  0.260888  ... -0.601439  1.998004  1.477351 -0.946682   \n",
       "3 -0.250227 -0.620329 -1.343189  ...  1.019492  0.576990 -0.752744  0.349346   \n",
       "4  0.303635  0.861126 -2.024719  ...  1.131879 -0.137990 -0.823316  0.402298   \n",
       "\n",
       "       pc16      pc17      pc18      pc19      pc20  size_category  \n",
       "0 -0.197543 -0.021839  0.688958  0.563603 -0.439596              0  \n",
       "1 -2.503167  0.499649  0.563706 -0.703319 -1.535718              0  \n",
       "2 -2.545144 -0.658411 -0.423618  0.860550 -1.195230              0  \n",
       "3 -0.040887  0.017843  0.332572  1.164745 -1.632741              0  \n",
       "4  0.844431  1.014944 -0.618231  0.822853 -1.794109              0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a data frame out of the new PCA features\n",
    "data_final=pd.concat([pd.DataFrame(pca_values[:,0:20],\n",
    "                    columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                'pc15','pc16','pc17','pc18','pc19','pc20']),\n",
    "                      y], axis = 1)\n",
    "data_final.size_category.replace(('small','large'),(0,1),inplace=True)\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into x and y\n",
    "array=data_final.values\n",
    "X_array=array[:,0:20]\n",
    "y_array=array[:,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and fitting the various models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T19:47:15.405464Z",
     "start_time": "2022-03-04T19:47:15.398468Z"
    }
   },
   "source": [
    "### Iteration- 1 (Base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:40:44.320053Z",
     "start_time": "2022-03-01T18:40:43.936288Z"
    }
   },
   "outputs": [],
   "source": [
    "#building model\n",
    "model = Sequential()\n",
    "model.add(Dense(20,input_dim= 20, kernel_initializer='uniform', activation = 'tanh'))\n",
    "model.add(Dense(12, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:40:48.765610Z",
     "start_time": "2022-03-01T18:40:48.739628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:41:01.596502Z",
     "start_time": "2022-03-01T18:40:59.833864Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "35/35 [==============================] - 2s 27ms/step - loss: 0.6877 - accuracy: 0.7572 - val_loss: 0.6841 - val_accuracy: 0.6784\n",
      "Epoch 2/250\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 0.6630 - accuracy: 0.7572 - val_loss: 0.6550 - val_accuracy: 0.6784\n",
      "Epoch 3/250\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 0.5837 - accuracy: 0.7572 - val_loss: 0.6247 - val_accuracy: 0.6784\n",
      "Epoch 4/250\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 0.5209 - accuracy: 0.7572 - val_loss: 0.6457 - val_accuracy: 0.6784\n",
      "Epoch 5/250\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 0.5015 - accuracy: 0.7572 - val_loss: 0.6466 - val_accuracy: 0.6784\n",
      "Epoch 6/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7572 - val_loss: 0.6554 - val_accuracy: 0.6784\n",
      "Epoch 7/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7572 - val_loss: 0.6534 - val_accuracy: 0.6784\n",
      "Epoch 8/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7572 - val_loss: 0.6630 - val_accuracy: 0.6784\n",
      "Epoch 9/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7572 - val_loss: 0.6543 - val_accuracy: 0.6784\n",
      "Epoch 10/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7572 - val_loss: 0.6607 - val_accuracy: 0.6784\n",
      "Epoch 11/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7572 - val_loss: 0.6584 - val_accuracy: 0.6784\n",
      "Epoch 12/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7572 - val_loss: 0.6590 - val_accuracy: 0.6784\n",
      "Epoch 13/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7572 - val_loss: 0.6637 - val_accuracy: 0.6784\n",
      "Epoch 14/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7572 - val_loss: 0.6682 - val_accuracy: 0.6784\n",
      "Epoch 15/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7861 - val_loss: 0.6622 - val_accuracy: 0.7018\n",
      "Epoch 16/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8035 - val_loss: 0.6619 - val_accuracy: 0.7018\n",
      "Epoch 17/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8064 - val_loss: 0.6658 - val_accuracy: 0.7018\n",
      "Epoch 18/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8092 - val_loss: 0.6588 - val_accuracy: 0.7076\n",
      "Epoch 19/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8208 - val_loss: 0.6629 - val_accuracy: 0.7135\n",
      "Epoch 20/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8237 - val_loss: 0.6591 - val_accuracy: 0.7193\n",
      "Epoch 21/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8324 - val_loss: 0.6669 - val_accuracy: 0.7368\n",
      "Epoch 22/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8439 - val_loss: 0.6803 - val_accuracy: 0.7368\n",
      "Epoch 23/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8439 - val_loss: 0.6735 - val_accuracy: 0.7427\n",
      "Epoch 24/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8468 - val_loss: 0.6820 - val_accuracy: 0.7485\n",
      "Epoch 25/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.8584 - val_loss: 0.6881 - val_accuracy: 0.7602\n",
      "Epoch 26/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8468 - val_loss: 0.7074 - val_accuracy: 0.7602\n",
      "Epoch 27/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8642 - val_loss: 0.7126 - val_accuracy: 0.7661\n",
      "Epoch 28/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8671 - val_loss: 0.7121 - val_accuracy: 0.7719\n",
      "Epoch 29/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8728 - val_loss: 0.7241 - val_accuracy: 0.7778\n",
      "Epoch 30/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8786 - val_loss: 0.7344 - val_accuracy: 0.7778\n",
      "Epoch 31/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8786 - val_loss: 0.7470 - val_accuracy: 0.7836\n",
      "Epoch 32/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.8844 - val_loss: 0.7562 - val_accuracy: 0.7836\n",
      "Epoch 33/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8699 - val_loss: 0.7655 - val_accuracy: 0.7895\n",
      "Epoch 34/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8873 - val_loss: 0.7789 - val_accuracy: 0.7895\n",
      "Epoch 35/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8931 - val_loss: 0.8021 - val_accuracy: 0.7895\n",
      "Epoch 36/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8960 - val_loss: 0.8221 - val_accuracy: 0.7778\n",
      "Epoch 37/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2982 - accuracy: 0.8902 - val_loss: 0.8239 - val_accuracy: 0.7778\n",
      "Epoch 38/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2939 - accuracy: 0.9017 - val_loss: 0.8511 - val_accuracy: 0.7895\n",
      "Epoch 39/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2869 - accuracy: 0.9046 - val_loss: 0.8383 - val_accuracy: 0.8070\n",
      "Epoch 40/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.8988 - val_loss: 0.8648 - val_accuracy: 0.7895\n",
      "Epoch 41/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.9075 - val_loss: 0.8869 - val_accuracy: 0.8012\n",
      "Epoch 42/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.9046 - val_loss: 0.9136 - val_accuracy: 0.7953\n",
      "Epoch 43/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.2648 - accuracy: 0.9104 - val_loss: 0.9229 - val_accuracy: 0.8070\n",
      "Epoch 44/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2581 - accuracy: 0.9220 - val_loss: 0.9432 - val_accuracy: 0.7953\n",
      "Epoch 45/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.9162 - val_loss: 0.9674 - val_accuracy: 0.8012\n",
      "Epoch 46/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2591 - accuracy: 0.9133 - val_loss: 0.9599 - val_accuracy: 0.8070\n",
      "Epoch 47/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.2515 - accuracy: 0.9277 - val_loss: 1.0026 - val_accuracy: 0.7953\n",
      "Epoch 48/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.9162 - val_loss: 0.9940 - val_accuracy: 0.8129\n",
      "Epoch 49/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.2425 - accuracy: 0.9335 - val_loss: 1.0477 - val_accuracy: 0.8070\n",
      "Epoch 50/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.2414 - accuracy: 0.9220 - val_loss: 1.0502 - val_accuracy: 0.8129\n",
      "Epoch 51/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2360 - accuracy: 0.9335 - val_loss: 1.0729 - val_accuracy: 0.8012\n",
      "Epoch 52/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9306 - val_loss: 1.1040 - val_accuracy: 0.8187\n",
      "Epoch 53/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2227 - accuracy: 0.9306 - val_loss: 1.1280 - val_accuracy: 0.8129\n",
      "Epoch 54/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9335 - val_loss: 1.1464 - val_accuracy: 0.8187\n",
      "Epoch 55/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9277 - val_loss: 1.1540 - val_accuracy: 0.8129\n",
      "Epoch 56/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.9451 - val_loss: 1.1986 - val_accuracy: 0.8304\n",
      "Epoch 57/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2040 - accuracy: 0.9277 - val_loss: 1.2288 - val_accuracy: 0.8304\n",
      "Epoch 58/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1910 - accuracy: 0.9509 - val_loss: 1.2727 - val_accuracy: 0.8129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9393 - val_loss: 1.2952 - val_accuracy: 0.8187\n",
      "Epoch 60/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1935 - accuracy: 0.9566 - val_loss: 1.3074 - val_accuracy: 0.8304\n",
      "Epoch 61/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9451 - val_loss: 1.3421 - val_accuracy: 0.8304\n",
      "Epoch 62/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1803 - accuracy: 0.9451 - val_loss: 1.3821 - val_accuracy: 0.8421\n",
      "Epoch 63/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1759 - accuracy: 0.9509 - val_loss: 1.4480 - val_accuracy: 0.8421\n",
      "Epoch 64/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1721 - accuracy: 0.9509 - val_loss: 1.4452 - val_accuracy: 0.8246\n",
      "Epoch 65/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9624 - val_loss: 1.5398 - val_accuracy: 0.8246\n",
      "Epoch 66/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1764 - accuracy: 0.9509 - val_loss: 1.5291 - val_accuracy: 0.8363\n",
      "Epoch 67/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9682 - val_loss: 1.5894 - val_accuracy: 0.8304\n",
      "Epoch 68/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.1577 - accuracy: 0.9509 - val_loss: 1.5948 - val_accuracy: 0.8304\n",
      "Epoch 69/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.9595 - val_loss: 1.6842 - val_accuracy: 0.8246\n",
      "Epoch 70/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9653 - val_loss: 1.6909 - val_accuracy: 0.8480\n",
      "Epoch 71/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1484 - accuracy: 0.9653 - val_loss: 1.7935 - val_accuracy: 0.8363\n",
      "Epoch 72/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.9682 - val_loss: 1.8043 - val_accuracy: 0.8363\n",
      "Epoch 73/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9711 - val_loss: 1.8154 - val_accuracy: 0.8480\n",
      "Epoch 74/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.9827 - val_loss: 1.9210 - val_accuracy: 0.8480\n",
      "Epoch 75/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1337 - accuracy: 0.9624 - val_loss: 1.9499 - val_accuracy: 0.8480\n",
      "Epoch 76/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.9769 - val_loss: 2.0090 - val_accuracy: 0.8304\n",
      "Epoch 77/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9740 - val_loss: 2.0113 - val_accuracy: 0.8596\n",
      "Epoch 78/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9740 - val_loss: 2.0371 - val_accuracy: 0.8480\n",
      "Epoch 79/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1254 - accuracy: 0.9740 - val_loss: 2.1243 - val_accuracy: 0.8480\n",
      "Epoch 80/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1290 - accuracy: 0.9740 - val_loss: 2.1538 - val_accuracy: 0.8538\n",
      "Epoch 81/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9769 - val_loss: 2.2276 - val_accuracy: 0.8480\n",
      "Epoch 82/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9740 - val_loss: 2.2414 - val_accuracy: 0.8480\n",
      "Epoch 83/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.1123 - accuracy: 0.9769 - val_loss: 2.3241 - val_accuracy: 0.8538\n",
      "Epoch 84/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9740 - val_loss: 2.3863 - val_accuracy: 0.8480\n",
      "Epoch 85/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.9740 - val_loss: 2.3302 - val_accuracy: 0.8538\n",
      "Epoch 86/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9740 - val_loss: 2.5175 - val_accuracy: 0.8421\n",
      "Epoch 87/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1240 - accuracy: 0.9798 - val_loss: 2.4389 - val_accuracy: 0.8421\n",
      "Epoch 88/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9769 - val_loss: 2.4565 - val_accuracy: 0.8480\n",
      "Epoch 89/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9884 - val_loss: 2.5485 - val_accuracy: 0.8480\n",
      "Epoch 90/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9798 - val_loss: 2.6258 - val_accuracy: 0.8538\n",
      "Epoch 91/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9769 - val_loss: 2.6934 - val_accuracy: 0.8187\n",
      "Epoch 92/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9740 - val_loss: 2.7204 - val_accuracy: 0.8538\n",
      "Epoch 93/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9827 - val_loss: 2.6327 - val_accuracy: 0.8596\n",
      "Epoch 94/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9827 - val_loss: 2.7085 - val_accuracy: 0.8655\n",
      "Epoch 95/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9855 - val_loss: 2.7568 - val_accuracy: 0.8655\n",
      "Epoch 96/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9798 - val_loss: 2.8089 - val_accuracy: 0.8655\n",
      "Epoch 97/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9827 - val_loss: 2.7948 - val_accuracy: 0.8713\n",
      "Epoch 98/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9884 - val_loss: 2.8504 - val_accuracy: 0.8596\n",
      "Epoch 99/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9769 - val_loss: 2.9847 - val_accuracy: 0.8480\n",
      "Epoch 100/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 0.9798 - val_loss: 2.9084 - val_accuracy: 0.8713\n",
      "Epoch 101/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9827 - val_loss: 2.9964 - val_accuracy: 0.8538\n",
      "Epoch 102/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.9827 - val_loss: 3.0438 - val_accuracy: 0.8480\n",
      "Epoch 103/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9798 - val_loss: 3.1333 - val_accuracy: 0.8655\n",
      "Epoch 104/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9884 - val_loss: 3.1818 - val_accuracy: 0.8538\n",
      "Epoch 105/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9798 - val_loss: 3.2603 - val_accuracy: 0.8596\n",
      "Epoch 106/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0976 - accuracy: 0.9740 - val_loss: 3.1408 - val_accuracy: 0.8655\n",
      "Epoch 107/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9855 - val_loss: 3.1920 - val_accuracy: 0.8772\n",
      "Epoch 108/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9855 - val_loss: 3.2348 - val_accuracy: 0.8655\n",
      "Epoch 109/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9884 - val_loss: 3.2850 - val_accuracy: 0.8772\n",
      "Epoch 110/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9798 - val_loss: 3.3162 - val_accuracy: 0.8772\n",
      "Epoch 111/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9827 - val_loss: 3.4214 - val_accuracy: 0.8713\n",
      "Epoch 112/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9827 - val_loss: 3.3598 - val_accuracy: 0.8713\n",
      "Epoch 113/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9855 - val_loss: 3.4377 - val_accuracy: 0.8772\n",
      "Epoch 114/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9855 - val_loss: 3.4668 - val_accuracy: 0.8655\n",
      "Epoch 115/250\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0756 - accuracy: 0.9884 - val_loss: 3.5585 - val_accuracy: 0.8655\n",
      "Epoch 116/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9769 - val_loss: 3.3944 - val_accuracy: 0.8713\n",
      "Epoch 117/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9798 - val_loss: 3.4053 - val_accuracy: 0.8655\n",
      "Epoch 118/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9798 - val_loss: 3.3748 - val_accuracy: 0.8596\n",
      "Epoch 119/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9884 - val_loss: 3.5098 - val_accuracy: 0.8655\n",
      "Epoch 120/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9884 - val_loss: 3.5075 - val_accuracy: 0.8655\n",
      "Epoch 121/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9884 - val_loss: 3.6061 - val_accuracy: 0.8655\n",
      "Epoch 122/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9798 - val_loss: 3.6724 - val_accuracy: 0.8304\n",
      "Epoch 123/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9913 - val_loss: 3.6632 - val_accuracy: 0.8480\n",
      "Epoch 124/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9855 - val_loss: 3.6275 - val_accuracy: 0.8480\n",
      "Epoch 125/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0749 - accuracy: 0.9769 - val_loss: 3.7208 - val_accuracy: 0.8538\n",
      "Epoch 126/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9884 - val_loss: 3.8241 - val_accuracy: 0.8421\n",
      "Epoch 127/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9855 - val_loss: 3.7127 - val_accuracy: 0.8596\n",
      "Epoch 128/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9798 - val_loss: 3.7370 - val_accuracy: 0.8655\n",
      "Epoch 129/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9913 - val_loss: 3.7637 - val_accuracy: 0.8655\n",
      "Epoch 130/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9884 - val_loss: 3.8058 - val_accuracy: 0.8538\n",
      "Epoch 131/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.9827 - val_loss: 3.8918 - val_accuracy: 0.8772\n",
      "Epoch 132/250\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0782 - accuracy: 0.9827 - val_loss: 3.8543 - val_accuracy: 0.8655\n",
      "Epoch 133/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9855 - val_loss: 3.9285 - val_accuracy: 0.8538\n",
      "Epoch 134/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9913 - val_loss: 4.0719 - val_accuracy: 0.8538\n",
      "Epoch 135/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9855 - val_loss: 4.0432 - val_accuracy: 0.8655\n",
      "Epoch 136/250\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0643 - accuracy: 0.9827 - val_loss: 4.1271 - val_accuracy: 0.8480\n",
      "Epoch 137/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9827 - val_loss: 4.0964 - val_accuracy: 0.8772\n",
      "Epoch 138/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9827 - val_loss: 4.1215 - val_accuracy: 0.8830\n",
      "Epoch 139/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9884 - val_loss: 4.1895 - val_accuracy: 0.8655\n",
      "Epoch 140/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9740 - val_loss: 4.1444 - val_accuracy: 0.8538\n",
      "Epoch 141/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0929 - accuracy: 0.9682 - val_loss: 4.1985 - val_accuracy: 0.8655\n",
      "Epoch 142/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9827 - val_loss: 4.3295 - val_accuracy: 0.8538\n",
      "Epoch 143/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9827 - val_loss: 4.2153 - val_accuracy: 0.8655\n",
      "Epoch 144/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9798 - val_loss: 4.3071 - val_accuracy: 0.8421\n",
      "Epoch 145/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9827 - val_loss: 4.2498 - val_accuracy: 0.8713\n",
      "Epoch 146/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.9855 - val_loss: 4.3413 - val_accuracy: 0.8596\n",
      "Epoch 147/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9913 - val_loss: 4.4077 - val_accuracy: 0.8655\n",
      "Epoch 148/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9884 - val_loss: 4.3756 - val_accuracy: 0.8713\n",
      "Epoch 149/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0642 - accuracy: 0.9827 - val_loss: 4.4438 - val_accuracy: 0.8713\n",
      "Epoch 150/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9913 - val_loss: 4.5729 - val_accuracy: 0.8596\n",
      "Epoch 151/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9884 - val_loss: 4.4842 - val_accuracy: 0.8713\n",
      "Epoch 152/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9827 - val_loss: 4.7199 - val_accuracy: 0.8655\n",
      "Epoch 153/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9884 - val_loss: 4.6019 - val_accuracy: 0.8772\n",
      "Epoch 154/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9913 - val_loss: 4.6732 - val_accuracy: 0.8538\n",
      "Epoch 155/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.9942 - val_loss: 4.7876 - val_accuracy: 0.8596\n",
      "Epoch 156/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.9884 - val_loss: 4.7577 - val_accuracy: 0.8655\n",
      "Epoch 157/250\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0551 - accuracy: 0.9855 - val_loss: 4.7705 - val_accuracy: 0.8480\n",
      "Epoch 158/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9913 - val_loss: 4.8073 - val_accuracy: 0.8772\n",
      "Epoch 159/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9913 - val_loss: 4.9118 - val_accuracy: 0.8596\n",
      "Epoch 160/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9884 - val_loss: 4.9145 - val_accuracy: 0.8655\n",
      "Epoch 161/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9884 - val_loss: 4.9825 - val_accuracy: 0.8655\n",
      "Epoch 162/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0460 - accuracy: 0.9942 - val_loss: 5.0125 - val_accuracy: 0.8713\n",
      "Epoch 163/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9884 - val_loss: 5.1498 - val_accuracy: 0.8421\n",
      "Epoch 164/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9855 - val_loss: 5.1142 - val_accuracy: 0.8421\n",
      "Epoch 165/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9798 - val_loss: 4.8259 - val_accuracy: 0.8480\n",
      "Epoch 166/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9682 - val_loss: 5.0377 - val_accuracy: 0.8187\n",
      "Epoch 167/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0632 - accuracy: 0.9827 - val_loss: 5.0149 - val_accuracy: 0.8421\n",
      "Epoch 168/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.9855 - val_loss: 4.9761 - val_accuracy: 0.8480\n",
      "Epoch 169/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0580 - accuracy: 0.9827 - val_loss: 4.9786 - val_accuracy: 0.8596\n",
      "Epoch 170/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9942 - val_loss: 5.0428 - val_accuracy: 0.8596\n",
      "Epoch 171/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0566 - accuracy: 0.9855 - val_loss: 5.0425 - val_accuracy: 0.8596\n",
      "Epoch 172/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9884 - val_loss: 5.1671 - val_accuracy: 0.8772\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0592 - accuracy: 0.9798 - val_loss: 5.1444 - val_accuracy: 0.8596\n",
      "Epoch 174/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9798 - val_loss: 5.0167 - val_accuracy: 0.8830\n",
      "Epoch 175/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 0.9798 - val_loss: 5.3218 - val_accuracy: 0.8596\n",
      "Epoch 176/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0789 - accuracy: 0.9798 - val_loss: 5.2929 - val_accuracy: 0.8363\n",
      "Epoch 177/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9624 - val_loss: 5.0014 - val_accuracy: 0.8596\n",
      "Epoch 178/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9653 - val_loss: 5.1038 - val_accuracy: 0.8480\n",
      "Epoch 179/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9711 - val_loss: 5.0369 - val_accuracy: 0.8480\n",
      "Epoch 180/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0620 - accuracy: 0.9884 - val_loss: 5.1170 - val_accuracy: 0.8538\n",
      "Epoch 181/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9798 - val_loss: 4.9765 - val_accuracy: 0.8421\n",
      "Epoch 182/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9884 - val_loss: 5.0920 - val_accuracy: 0.8480\n",
      "Epoch 183/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9884 - val_loss: 5.1287 - val_accuracy: 0.8538\n",
      "Epoch 184/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 0.9855 - val_loss: 5.2049 - val_accuracy: 0.8596\n",
      "Epoch 185/250\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0519 - accuracy: 0.9855 - val_loss: 5.2249 - val_accuracy: 0.8480\n",
      "Epoch 186/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0559 - accuracy: 0.9855 - val_loss: 5.2323 - val_accuracy: 0.8596\n",
      "Epoch 187/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0499 - accuracy: 0.9884 - val_loss: 5.3295 - val_accuracy: 0.8480\n",
      "Epoch 188/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9827 - val_loss: 5.3316 - val_accuracy: 0.8538\n",
      "Epoch 189/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9798 - val_loss: 5.3711 - val_accuracy: 0.8480\n",
      "Epoch 190/250\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 5.4062 - val_accuracy: 0.8538\n",
      "Epoch 191/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9884 - val_loss: 5.4082 - val_accuracy: 0.8596\n",
      "Epoch 192/250\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9855 - val_loss: 5.4826 - val_accuracy: 0.8596\n",
      "Epoch 193/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9884 - val_loss: 5.4831 - val_accuracy: 0.8596\n",
      "Epoch 194/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9855 - val_loss: 5.5634 - val_accuracy: 0.8596\n",
      "Epoch 195/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9913 - val_loss: 5.5602 - val_accuracy: 0.8596\n",
      "Epoch 196/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9884 - val_loss: 5.6290 - val_accuracy: 0.8538\n",
      "Epoch 197/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9855 - val_loss: 5.6741 - val_accuracy: 0.8596\n",
      "Epoch 198/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9913 - val_loss: 5.7271 - val_accuracy: 0.8538\n",
      "Epoch 199/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9855 - val_loss: 5.7182 - val_accuracy: 0.8596\n",
      "Epoch 200/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9884 - val_loss: 5.7699 - val_accuracy: 0.8655\n",
      "Epoch 201/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0549 - accuracy: 0.9827 - val_loss: 5.9327 - val_accuracy: 0.8538\n",
      "Epoch 202/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0907 - accuracy: 0.9740 - val_loss: 5.9041 - val_accuracy: 0.8421\n",
      "Epoch 203/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9827 - val_loss: 5.4994 - val_accuracy: 0.8655\n",
      "Epoch 204/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9827 - val_loss: 5.6560 - val_accuracy: 0.8538\n",
      "Epoch 205/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9769 - val_loss: 5.6284 - val_accuracy: 0.8421\n",
      "Epoch 206/250\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0782 - accuracy: 0.9827 - val_loss: 5.5159 - val_accuracy: 0.8538\n",
      "Epoch 207/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9798 - val_loss: 5.3042 - val_accuracy: 0.8655\n",
      "Epoch 208/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9769 - val_loss: 5.4866 - val_accuracy: 0.8655\n",
      "Epoch 209/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0668 - accuracy: 0.9798 - val_loss: 5.4135 - val_accuracy: 0.8772\n",
      "Epoch 210/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9884 - val_loss: 5.5562 - val_accuracy: 0.8596\n",
      "Epoch 211/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9884 - val_loss: 5.5209 - val_accuracy: 0.8655\n",
      "Epoch 212/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9855 - val_loss: 5.6104 - val_accuracy: 0.8596\n",
      "Epoch 213/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9884 - val_loss: 5.5855 - val_accuracy: 0.8596\n",
      "Epoch 214/250\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0478 - accuracy: 0.9884 - val_loss: 5.6585 - val_accuracy: 0.8713\n",
      "Epoch 215/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 5.7171 - val_accuracy: 0.8596\n",
      "Epoch 216/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9855 - val_loss: 5.6769 - val_accuracy: 0.8596\n",
      "Epoch 217/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.9913 - val_loss: 5.7775 - val_accuracy: 0.8596\n",
      "Epoch 218/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9884 - val_loss: 5.8362 - val_accuracy: 0.8655\n",
      "Epoch 219/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0496 - accuracy: 0.9855 - val_loss: 5.8285 - val_accuracy: 0.8655\n",
      "Epoch 220/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9913 - val_loss: 5.8244 - val_accuracy: 0.8655\n",
      "Epoch 221/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9855 - val_loss: 5.9599 - val_accuracy: 0.8596\n",
      "Epoch 222/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 0.9855 - val_loss: 5.8729 - val_accuracy: 0.8596\n",
      "Epoch 223/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9884 - val_loss: 6.0090 - val_accuracy: 0.8596\n",
      "Epoch 224/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9884 - val_loss: 5.8014 - val_accuracy: 0.8655\n",
      "Epoch 225/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 5.9409 - val_accuracy: 0.8596\n",
      "Epoch 226/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 5.9875 - val_accuracy: 0.8596\n",
      "Epoch 227/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0445 - accuracy: 0.9913 - val_loss: 5.9766 - val_accuracy: 0.8596\n",
      "Epoch 228/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9884 - val_loss: 6.0419 - val_accuracy: 0.8596\n",
      "Epoch 229/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0632 - accuracy: 0.9798 - val_loss: 5.9448 - val_accuracy: 0.8596\n",
      "Epoch 230/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9855 - val_loss: 5.7877 - val_accuracy: 0.8655\n",
      "Epoch 231/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9913 - val_loss: 5.9290 - val_accuracy: 0.8596\n",
      "Epoch 232/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9798 - val_loss: 5.8132 - val_accuracy: 0.8187\n",
      "Epoch 233/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3483 - accuracy: 0.9653 - val_loss: 5.2300 - val_accuracy: 0.8596\n",
      "Epoch 234/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9682 - val_loss: 5.4233 - val_accuracy: 0.8421\n",
      "Epoch 235/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9942 - val_loss: 5.3418 - val_accuracy: 0.8655\n",
      "Epoch 236/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9855 - val_loss: 5.5281 - val_accuracy: 0.8363\n",
      "Epoch 237/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 5.4305 - val_accuracy: 0.8480\n",
      "Epoch 238/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9913 - val_loss: 5.4833 - val_accuracy: 0.8480\n",
      "Epoch 239/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9855 - val_loss: 5.5300 - val_accuracy: 0.8480\n",
      "Epoch 240/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9942 - val_loss: 5.5716 - val_accuracy: 0.8538\n",
      "Epoch 241/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 5.6062 - val_accuracy: 0.8538\n",
      "Epoch 242/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9942 - val_loss: 5.6483 - val_accuracy: 0.8538\n",
      "Epoch 243/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0936 - accuracy: 0.9798 - val_loss: 5.5494 - val_accuracy: 0.8480\n",
      "Epoch 244/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9884 - val_loss: 5.6640 - val_accuracy: 0.8480\n",
      "Epoch 245/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9769 - val_loss: 5.5983 - val_accuracy: 0.8596\n",
      "Epoch 246/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9827 - val_loss: 5.6006 - val_accuracy: 0.8596\n",
      "Epoch 247/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9884 - val_loss: 5.7441 - val_accuracy: 0.8538\n",
      "Epoch 248/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9884 - val_loss: 5.7490 - val_accuracy: 0.8538\n",
      "Epoch 249/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9913 - val_loss: 5.7882 - val_accuracy: 0.8538\n",
      "Epoch 250/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9884 - val_loss: 5.8558 - val_accuracy: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c007f3dc10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_array, y_array, validation_split=0.33, epochs=250, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:43:17.028050Z",
     "start_time": "2022-03-01T18:43:16.953095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9653 - accuracy: 0.9497\n",
      "accuracy: 94.97%\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the best value\n",
    "scores=model.evaluate(X_array,y_array)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration- 2 (Model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building another model with different features\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(20,input_dim= 20, kernel_initializer='uniform', activation = 'sigmoid'))\n",
    "model_1.add(Dense(10, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model_1.add(Dense(5, kernel_initializer='uniform', activation='relu'))\n",
    "model_1.add(Dense(1, kernel_initializer='uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "35/35 [==============================] - 2s 13ms/step - loss: 1.0383 - accuracy: 0.7572 - val_loss: 1.1277 - val_accuracy: 0.6784\n",
      "Epoch 2/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.7747 - accuracy: 0.7572 - val_loss: 0.9168 - val_accuracy: 0.6784\n",
      "Epoch 3/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6611 - accuracy: 0.7572 - val_loss: 0.7838 - val_accuracy: 0.6784\n",
      "Epoch 4/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7572 - val_loss: 0.7115 - val_accuracy: 0.6784\n",
      "Epoch 5/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.7572 - val_loss: 0.6755 - val_accuracy: 0.6784\n",
      "Epoch 6/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7572 - val_loss: 0.6571 - val_accuracy: 0.6784\n",
      "Epoch 7/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.7572 - val_loss: 0.6502 - val_accuracy: 0.6784\n",
      "Epoch 8/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5504 - accuracy: 0.7572 - val_loss: 0.6453 - val_accuracy: 0.6784\n",
      "Epoch 9/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.7572 - val_loss: 0.6387 - val_accuracy: 0.6784\n",
      "Epoch 10/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.7572 - val_loss: 0.6424 - val_accuracy: 0.6784\n",
      "Epoch 11/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7572 - val_loss: 0.6418 - val_accuracy: 0.6784\n",
      "Epoch 12/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7572 - val_loss: 0.6393 - val_accuracy: 0.6784\n",
      "Epoch 13/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5470 - accuracy: 0.7572 - val_loss: 0.6404 - val_accuracy: 0.6784\n",
      "Epoch 14/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7572 - val_loss: 0.6390 - val_accuracy: 0.6784\n",
      "Epoch 15/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.7572 - val_loss: 0.6428 - val_accuracy: 0.6784\n",
      "Epoch 16/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5452 - accuracy: 0.7572 - val_loss: 0.6380 - val_accuracy: 0.6784\n",
      "Epoch 17/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5455 - accuracy: 0.7572 - val_loss: 0.6399 - val_accuracy: 0.6784\n",
      "Epoch 18/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.7572 - val_loss: 0.6375 - val_accuracy: 0.6784\n",
      "Epoch 19/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5439 - accuracy: 0.7572 - val_loss: 0.6386 - val_accuracy: 0.6784\n",
      "Epoch 20/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7572 - val_loss: 0.6349 - val_accuracy: 0.6784\n",
      "Epoch 21/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5438 - accuracy: 0.7572 - val_loss: 0.6391 - val_accuracy: 0.6784\n",
      "Epoch 22/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7572 - val_loss: 0.6387 - val_accuracy: 0.6784\n",
      "Epoch 23/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7572 - val_loss: 0.6356 - val_accuracy: 0.6784\n",
      "Epoch 24/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7572 - val_loss: 0.6407 - val_accuracy: 0.6784\n",
      "Epoch 25/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.7572 - val_loss: 0.6387 - val_accuracy: 0.6784\n",
      "Epoch 26/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5404 - accuracy: 0.7572 - val_loss: 0.6334 - val_accuracy: 0.6784\n",
      "Epoch 27/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7572 - val_loss: 0.6329 - val_accuracy: 0.6784\n",
      "Epoch 28/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.7572 - val_loss: 0.6387 - val_accuracy: 0.6784\n",
      "Epoch 29/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7572 - val_loss: 0.6367 - val_accuracy: 0.6784\n",
      "Epoch 30/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7572 - val_loss: 0.6362 - val_accuracy: 0.6784\n",
      "Epoch 31/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5379 - accuracy: 0.7572 - val_loss: 0.6344 - val_accuracy: 0.6784\n",
      "Epoch 32/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7572 - val_loss: 0.6361 - val_accuracy: 0.6784\n",
      "Epoch 33/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7572 - val_loss: 0.6332 - val_accuracy: 0.6784\n",
      "Epoch 34/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5362 - accuracy: 0.7572 - val_loss: 0.6375 - val_accuracy: 0.6784\n",
      "Epoch 35/150\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.5367 - accuracy: 0.7572 - val_loss: 0.6317 - val_accuracy: 0.6784\n",
      "Epoch 36/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5367 - accuracy: 0.7572 - val_loss: 0.6345 - val_accuracy: 0.6784\n",
      "Epoch 37/150\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.5345 - accuracy: 0.7572 - val_loss: 0.6288 - val_accuracy: 0.6784\n",
      "Epoch 38/150\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.5335 - accuracy: 0.7572 - val_loss: 0.6329 - val_accuracy: 0.6784\n",
      "Epoch 39/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5332 - accuracy: 0.7572 - val_loss: 0.6300 - val_accuracy: 0.6784\n",
      "Epoch 40/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5324 - accuracy: 0.7572 - val_loss: 0.6299 - val_accuracy: 0.6784\n",
      "Epoch 41/150\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.5314 - accuracy: 0.7572 - val_loss: 0.6329 - val_accuracy: 0.6784\n",
      "Epoch 42/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.7572 - val_loss: 0.6263 - val_accuracy: 0.6784\n",
      "Epoch 43/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5315 - accuracy: 0.7572 - val_loss: 0.6223 - val_accuracy: 0.6784\n",
      "Epoch 44/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.7572 - val_loss: 0.6272 - val_accuracy: 0.6784\n",
      "Epoch 45/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5321 - accuracy: 0.7572 - val_loss: 0.6289 - val_accuracy: 0.6784\n",
      "Epoch 46/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5278 - accuracy: 0.7572 - val_loss: 0.6264 - val_accuracy: 0.6784\n",
      "Epoch 47/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7572 - val_loss: 0.6291 - val_accuracy: 0.6784\n",
      "Epoch 48/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7572 - val_loss: 0.6228 - val_accuracy: 0.6784\n",
      "Epoch 49/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7572 - val_loss: 0.6266 - val_accuracy: 0.6784\n",
      "Epoch 50/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.7572 - val_loss: 0.6222 - val_accuracy: 0.6784\n",
      "Epoch 51/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7572 - val_loss: 0.6228 - val_accuracy: 0.6784\n",
      "Epoch 52/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5218 - accuracy: 0.7572 - val_loss: 0.6233 - val_accuracy: 0.6784\n",
      "Epoch 53/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5216 - accuracy: 0.7572 - val_loss: 0.6261 - val_accuracy: 0.6784\n",
      "Epoch 54/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5196 - accuracy: 0.7572 - val_loss: 0.6219 - val_accuracy: 0.6784\n",
      "Epoch 55/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5194 - accuracy: 0.7572 - val_loss: 0.6183 - val_accuracy: 0.6784\n",
      "Epoch 56/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7572 - val_loss: 0.6202 - val_accuracy: 0.6784\n",
      "Epoch 57/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7572 - val_loss: 0.6192 - val_accuracy: 0.6784\n",
      "Epoch 58/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7572 - val_loss: 0.6149 - val_accuracy: 0.6784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7572 - val_loss: 0.6137 - val_accuracy: 0.6784\n",
      "Epoch 60/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.7572 - val_loss: 0.6141 - val_accuracy: 0.6784\n",
      "Epoch 61/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.7572 - val_loss: 0.6176 - val_accuracy: 0.6784\n",
      "Epoch 62/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5087 - accuracy: 0.7572 - val_loss: 0.6125 - val_accuracy: 0.6784\n",
      "Epoch 63/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.7572 - val_loss: 0.6107 - val_accuracy: 0.6784\n",
      "Epoch 64/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5049 - accuracy: 0.7572 - val_loss: 0.6114 - val_accuracy: 0.6784\n",
      "Epoch 65/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7572 - val_loss: 0.6078 - val_accuracy: 0.6784\n",
      "Epoch 66/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7572 - val_loss: 0.6094 - val_accuracy: 0.6784\n",
      "Epoch 67/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4994 - accuracy: 0.7572 - val_loss: 0.6019 - val_accuracy: 0.6784\n",
      "Epoch 68/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7572 - val_loss: 0.6012 - val_accuracy: 0.6784\n",
      "Epoch 69/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7572 - val_loss: 0.6022 - val_accuracy: 0.6784\n",
      "Epoch 70/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7572 - val_loss: 0.5987 - val_accuracy: 0.6784\n",
      "Epoch 71/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7572 - val_loss: 0.5974 - val_accuracy: 0.6784\n",
      "Epoch 72/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7572 - val_loss: 0.6015 - val_accuracy: 0.6784\n",
      "Epoch 73/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7572 - val_loss: 0.5882 - val_accuracy: 0.6784\n",
      "Epoch 74/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7572 - val_loss: 0.5870 - val_accuracy: 0.6784\n",
      "Epoch 75/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7572 - val_loss: 0.5859 - val_accuracy: 0.6784\n",
      "Epoch 76/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7572 - val_loss: 0.5893 - val_accuracy: 0.6784\n",
      "Epoch 77/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7572 - val_loss: 0.5846 - val_accuracy: 0.6784\n",
      "Epoch 78/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7688 - val_loss: 0.5824 - val_accuracy: 0.6784\n",
      "Epoch 79/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7572 - val_loss: 0.5835 - val_accuracy: 0.6784\n",
      "Epoch 80/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7803 - val_loss: 0.5708 - val_accuracy: 0.7018\n",
      "Epoch 81/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8006 - val_loss: 0.5704 - val_accuracy: 0.7018\n",
      "Epoch 82/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7919 - val_loss: 0.5714 - val_accuracy: 0.7018\n",
      "Epoch 83/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8179 - val_loss: 0.5647 - val_accuracy: 0.7135\n",
      "Epoch 84/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8064 - val_loss: 0.5728 - val_accuracy: 0.7135\n",
      "Epoch 85/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.8092 - val_loss: 0.5576 - val_accuracy: 0.7310\n",
      "Epoch 86/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8121 - val_loss: 0.5593 - val_accuracy: 0.7310\n",
      "Epoch 87/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8266 - val_loss: 0.5513 - val_accuracy: 0.7251\n",
      "Epoch 88/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8324 - val_loss: 0.5547 - val_accuracy: 0.7251\n",
      "Epoch 89/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8295 - val_loss: 0.5517 - val_accuracy: 0.7310\n",
      "Epoch 90/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8295 - val_loss: 0.5451 - val_accuracy: 0.7427\n",
      "Epoch 91/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8324 - val_loss: 0.5492 - val_accuracy: 0.7427\n",
      "Epoch 92/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8353 - val_loss: 0.5492 - val_accuracy: 0.7427\n",
      "Epoch 93/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8382 - val_loss: 0.5536 - val_accuracy: 0.7485\n",
      "Epoch 94/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8353 - val_loss: 0.6803 - val_accuracy: 0.7427\n",
      "Epoch 95/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8353 - val_loss: 0.6723 - val_accuracy: 0.7661\n",
      "Epoch 96/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8468 - val_loss: 0.6574 - val_accuracy: 0.7719\n",
      "Epoch 97/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8410 - val_loss: 0.6617 - val_accuracy: 0.7719\n",
      "Epoch 98/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8613 - val_loss: 0.6452 - val_accuracy: 0.7719\n",
      "Epoch 99/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8613 - val_loss: 0.6551 - val_accuracy: 0.7719\n",
      "Epoch 100/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8526 - val_loss: 0.6558 - val_accuracy: 0.7661\n",
      "Epoch 101/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8526 - val_loss: 0.6418 - val_accuracy: 0.7778\n",
      "Epoch 102/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.8642 - val_loss: 0.6374 - val_accuracy: 0.7778\n",
      "Epoch 103/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8613 - val_loss: 0.6359 - val_accuracy: 0.7719\n",
      "Epoch 104/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8642 - val_loss: 0.6355 - val_accuracy: 0.7719\n",
      "Epoch 105/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8699 - val_loss: 0.6320 - val_accuracy: 0.7661\n",
      "Epoch 106/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8699 - val_loss: 0.6338 - val_accuracy: 0.7719\n",
      "Epoch 107/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8699 - val_loss: 0.6382 - val_accuracy: 0.7719\n",
      "Epoch 108/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8699 - val_loss: 0.6357 - val_accuracy: 0.7661\n",
      "Epoch 109/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8671 - val_loss: 0.6955 - val_accuracy: 0.7719\n",
      "Epoch 110/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8671 - val_loss: 0.6938 - val_accuracy: 0.7778\n",
      "Epoch 111/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8671 - val_loss: 0.6933 - val_accuracy: 0.7778\n",
      "Epoch 112/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8642 - val_loss: 0.6856 - val_accuracy: 0.7836\n",
      "Epoch 113/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.8671 - val_loss: 0.6793 - val_accuracy: 0.8012\n",
      "Epoch 114/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8671 - val_loss: 0.7518 - val_accuracy: 0.7836\n",
      "Epoch 115/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8671 - val_loss: 0.7445 - val_accuracy: 0.7953\n",
      "Epoch 116/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8671 - val_loss: 0.6811 - val_accuracy: 0.7953\n",
      "Epoch 117/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3170 - accuracy: 0.8699 - val_loss: 0.6722 - val_accuracy: 0.8012\n",
      "Epoch 118/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8642 - val_loss: 0.7408 - val_accuracy: 0.7953\n",
      "Epoch 119/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8699 - val_loss: 0.6661 - val_accuracy: 0.8070\n",
      "Epoch 120/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8642 - val_loss: 0.6651 - val_accuracy: 0.7953\n",
      "Epoch 121/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8642 - val_loss: 0.6633 - val_accuracy: 0.7953\n",
      "Epoch 122/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8613 - val_loss: 0.7324 - val_accuracy: 0.8012\n",
      "Epoch 123/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8642 - val_loss: 0.6645 - val_accuracy: 0.8070\n",
      "Epoch 124/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.8642 - val_loss: 0.6621 - val_accuracy: 0.8012\n",
      "Epoch 125/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8699 - val_loss: 0.7315 - val_accuracy: 0.7953\n",
      "Epoch 126/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8642 - val_loss: 0.6608 - val_accuracy: 0.8129\n",
      "Epoch 127/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8671 - val_loss: 0.6642 - val_accuracy: 0.8012\n",
      "Epoch 128/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8671 - val_loss: 0.6649 - val_accuracy: 0.8070\n",
      "Epoch 129/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8699 - val_loss: 0.6571 - val_accuracy: 0.8070\n",
      "Epoch 130/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8671 - val_loss: 0.7199 - val_accuracy: 0.8070\n",
      "Epoch 131/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.8613 - val_loss: 0.6589 - val_accuracy: 0.8129\n",
      "Epoch 132/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.8671 - val_loss: 0.6538 - val_accuracy: 0.8187\n",
      "Epoch 133/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2996 - accuracy: 0.8613 - val_loss: 0.7190 - val_accuracy: 0.8129\n",
      "Epoch 134/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.8642 - val_loss: 0.6694 - val_accuracy: 0.8070\n",
      "Epoch 135/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.8613 - val_loss: 0.6553 - val_accuracy: 0.8070\n",
      "Epoch 136/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2907 - accuracy: 0.8613 - val_loss: 0.6598 - val_accuracy: 0.8187\n",
      "Epoch 137/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2915 - accuracy: 0.8642 - val_loss: 0.6595 - val_accuracy: 0.8129\n",
      "Epoch 138/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2887 - accuracy: 0.8671 - val_loss: 0.7161 - val_accuracy: 0.8187\n",
      "Epoch 139/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8671 - val_loss: 0.7160 - val_accuracy: 0.8187\n",
      "Epoch 140/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8613 - val_loss: 0.6756 - val_accuracy: 0.8129\n",
      "Epoch 141/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.8699 - val_loss: 0.7130 - val_accuracy: 0.8012\n",
      "Epoch 142/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.8699 - val_loss: 0.7133 - val_accuracy: 0.8012\n",
      "Epoch 143/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2905 - accuracy: 0.8642 - val_loss: 0.7776 - val_accuracy: 0.8129\n",
      "Epoch 144/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8699 - val_loss: 0.7170 - val_accuracy: 0.8187\n",
      "Epoch 145/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.8671 - val_loss: 0.7728 - val_accuracy: 0.8246\n",
      "Epoch 146/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.8671 - val_loss: 0.7068 - val_accuracy: 0.8129\n",
      "Epoch 147/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8699 - val_loss: 0.7090 - val_accuracy: 0.8304\n",
      "Epoch 148/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8584 - val_loss: 0.7359 - val_accuracy: 0.7895\n",
      "Epoch 149/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2900 - accuracy: 0.8671 - val_loss: 0.7055 - val_accuracy: 0.8129\n",
      "Epoch 150/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.8728 - val_loss: 0.7042 - val_accuracy: 0.8129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c00a4e7b80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1.fit(X_array, y_array, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8491\n",
      "accuracy: 84.91%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the model\n",
    "scores_1=model_1.evaluate(X_array,y_array)\n",
    "print(\"%s: %.2f%%\" % (model_1.metrics_names[1], scores_1[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T19:45:46.711416Z",
     "start_time": "2022-03-04T19:45:46.697423Z"
    }
   },
   "source": [
    "### Iteration- 3(Model-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building another model with different features\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(12,input_dim= 20, kernel_initializer='uniform', activation = 'sigmoid'))\n",
    "model_2.add(Dense(6, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model_2.add(Dense(3, kernel_initializer='uniform', activation='relu'))\n",
    "model_2.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 1s 12ms/step - loss: 0.6885 - accuracy: 0.7572 - val_loss: 0.6863 - val_accuracy: 0.6784\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.7572 - val_loss: 0.6771 - val_accuracy: 0.6784\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.6606 - accuracy: 0.7572 - val_loss: 0.6646 - val_accuracy: 0.6784\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6383 - accuracy: 0.7572 - val_loss: 0.6504 - val_accuracy: 0.6784\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.7572 - val_loss: 0.6370 - val_accuracy: 0.6784\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7572 - val_loss: 0.6293 - val_accuracy: 0.6784\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.7572 - val_loss: 0.6259 - val_accuracy: 0.6784\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.7572 - val_loss: 0.6267 - val_accuracy: 0.6784\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7572 - val_loss: 0.6293 - val_accuracy: 0.6784\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7572 - val_loss: 0.6314 - val_accuracy: 0.6784\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7572 - val_loss: 0.6345 - val_accuracy: 0.6784\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5455 - accuracy: 0.7572 - val_loss: 0.6369 - val_accuracy: 0.6784\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.7572 - val_loss: 0.6377 - val_accuracy: 0.6784\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5437 - accuracy: 0.7572 - val_loss: 0.6399 - val_accuracy: 0.6784\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.7572 - val_loss: 0.6395 - val_accuracy: 0.6784\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5418 - accuracy: 0.7572 - val_loss: 0.6388 - val_accuracy: 0.6784\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5411 - accuracy: 0.7572 - val_loss: 0.6389 - val_accuracy: 0.6784\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5404 - accuracy: 0.7572 - val_loss: 0.6375 - val_accuracy: 0.6784\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5396 - accuracy: 0.7572 - val_loss: 0.6384 - val_accuracy: 0.6784\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5387 - accuracy: 0.7572 - val_loss: 0.6391 - val_accuracy: 0.6784\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5380 - accuracy: 0.7572 - val_loss: 0.6383 - val_accuracy: 0.6784\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5375 - accuracy: 0.7572 - val_loss: 0.6385 - val_accuracy: 0.6784\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7572 - val_loss: 0.6373 - val_accuracy: 0.6784\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7572 - val_loss: 0.6379 - val_accuracy: 0.6784\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7572 - val_loss: 0.6384 - val_accuracy: 0.6784\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7572 - val_loss: 0.6377 - val_accuracy: 0.6784\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7572 - val_loss: 0.6367 - val_accuracy: 0.6784\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7572 - val_loss: 0.6370 - val_accuracy: 0.6784\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5321 - accuracy: 0.7572 - val_loss: 0.6370 - val_accuracy: 0.6784\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5314 - accuracy: 0.7572 - val_loss: 0.6370 - val_accuracy: 0.6784\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7572 - val_loss: 0.6379 - val_accuracy: 0.6784\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7572 - val_loss: 0.6353 - val_accuracy: 0.6784\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7572 - val_loss: 0.6370 - val_accuracy: 0.6784\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.5281 - accuracy: 0.7572 - val_loss: 0.6363 - val_accuracy: 0.6784\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.7572 - val_loss: 0.6350 - val_accuracy: 0.6784\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7572 - val_loss: 0.6353 - val_accuracy: 0.6784\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.7572 - val_loss: 0.6351 - val_accuracy: 0.6784\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5248 - accuracy: 0.7572 - val_loss: 0.6349 - val_accuracy: 0.6784\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5240 - accuracy: 0.7572 - val_loss: 0.6354 - val_accuracy: 0.6784\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7572 - val_loss: 0.6334 - val_accuracy: 0.6784\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.5222 - accuracy: 0.7572 - val_loss: 0.6358 - val_accuracy: 0.6784\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7572 - val_loss: 0.6340 - val_accuracy: 0.6784\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7572 - val_loss: 0.6341 - val_accuracy: 0.6784\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7572 - val_loss: 0.6336 - val_accuracy: 0.6784\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7572 - val_loss: 0.6315 - val_accuracy: 0.6784\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7572 - val_loss: 0.6310 - val_accuracy: 0.6784\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7572 - val_loss: 0.6322 - val_accuracy: 0.6784\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7572 - val_loss: 0.6329 - val_accuracy: 0.6784\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7572 - val_loss: 0.6324 - val_accuracy: 0.6784\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7572 - val_loss: 0.6336 - val_accuracy: 0.6784\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.5120 - accuracy: 0.7572 - val_loss: 0.6320 - val_accuracy: 0.6784\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.7572 - val_loss: 0.6291 - val_accuracy: 0.6784\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7572 - val_loss: 0.6299 - val_accuracy: 0.6784\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7572 - val_loss: 0.6302 - val_accuracy: 0.6784\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7572 - val_loss: 0.6273 - val_accuracy: 0.6784\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7572 - val_loss: 0.6261 - val_accuracy: 0.6784\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7572 - val_loss: 0.6262 - val_accuracy: 0.6784\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7572 - val_loss: 0.6276 - val_accuracy: 0.6784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7572 - val_loss: 0.6263 - val_accuracy: 0.6784\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7572 - val_loss: 0.6240 - val_accuracy: 0.6784\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7572 - val_loss: 0.6246 - val_accuracy: 0.6784\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7572 - val_loss: 0.6260 - val_accuracy: 0.6784\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7572 - val_loss: 0.6212 - val_accuracy: 0.6784\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7572 - val_loss: 0.6240 - val_accuracy: 0.6784\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.7572 - val_loss: 0.6208 - val_accuracy: 0.6784\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7572 - val_loss: 0.6218 - val_accuracy: 0.6784\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7572 - val_loss: 0.6210 - val_accuracy: 0.6784\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7572 - val_loss: 0.6188 - val_accuracy: 0.6784\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.7572 - val_loss: 0.6171 - val_accuracy: 0.6784\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7572 - val_loss: 0.6163 - val_accuracy: 0.6784\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7572 - val_loss: 0.6138 - val_accuracy: 0.6784\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7572 - val_loss: 0.6141 - val_accuracy: 0.6784\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7572 - val_loss: 0.6136 - val_accuracy: 0.6784\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7572 - val_loss: 0.6139 - val_accuracy: 0.6784\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7572 - val_loss: 0.6116 - val_accuracy: 0.6784\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7572 - val_loss: 0.6113 - val_accuracy: 0.6784\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7572 - val_loss: 0.6101 - val_accuracy: 0.6784\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7572 - val_loss: 0.6078 - val_accuracy: 0.6784\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7572 - val_loss: 0.6083 - val_accuracy: 0.6784\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7572 - val_loss: 0.6046 - val_accuracy: 0.6784\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7572 - val_loss: 0.6023 - val_accuracy: 0.6784\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7572 - val_loss: 0.6041 - val_accuracy: 0.6784\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7572 - val_loss: 0.6033 - val_accuracy: 0.6784\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7572 - val_loss: 0.6040 - val_accuracy: 0.6784\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7572 - val_loss: 0.5981 - val_accuracy: 0.6784\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7572 - val_loss: 0.5977 - val_accuracy: 0.6784\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7572 - val_loss: 0.5965 - val_accuracy: 0.6784\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7572 - val_loss: 0.5969 - val_accuracy: 0.6784\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7572 - val_loss: 0.5930 - val_accuracy: 0.6784\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7572 - val_loss: 0.5918 - val_accuracy: 0.6784\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7572 - val_loss: 0.5929 - val_accuracy: 0.6784\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7572 - val_loss: 0.5869 - val_accuracy: 0.6784\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7572 - val_loss: 0.5890 - val_accuracy: 0.6784\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7572 - val_loss: 0.5859 - val_accuracy: 0.6784\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7572 - val_loss: 0.5838 - val_accuracy: 0.6784\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7572 - val_loss: 0.5847 - val_accuracy: 0.6784\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7601 - val_loss: 0.5824 - val_accuracy: 0.7018\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7717 - val_loss: 0.5827 - val_accuracy: 0.7018\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7832 - val_loss: 0.5790 - val_accuracy: 0.7018\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7948 - val_loss: 0.5768 - val_accuracy: 0.7018\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7948 - val_loss: 0.5725 - val_accuracy: 0.7076\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7977 - val_loss: 0.5737 - val_accuracy: 0.7135\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7977 - val_loss: 0.5739 - val_accuracy: 0.7135\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8006 - val_loss: 0.5698 - val_accuracy: 0.7193\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8006 - val_loss: 0.5688 - val_accuracy: 0.7193\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8092 - val_loss: 0.5655 - val_accuracy: 0.7193\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.8121 - val_loss: 0.5624 - val_accuracy: 0.7251\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8179 - val_loss: 0.5654 - val_accuracy: 0.7251\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8179 - val_loss: 0.5595 - val_accuracy: 0.7310\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8237 - val_loss: 0.5580 - val_accuracy: 0.7310\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.8237 - val_loss: 0.5589 - val_accuracy: 0.7310\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8237 - val_loss: 0.5560 - val_accuracy: 0.7368\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8266 - val_loss: 0.5543 - val_accuracy: 0.7368\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8266 - val_loss: 0.5535 - val_accuracy: 0.7368\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8324 - val_loss: 0.5472 - val_accuracy: 0.7485\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8324 - val_loss: 0.5445 - val_accuracy: 0.7485\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8324 - val_loss: 0.5472 - val_accuracy: 0.7485\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8353 - val_loss: 0.5420 - val_accuracy: 0.7544\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8353 - val_loss: 0.5397 - val_accuracy: 0.7485\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8324 - val_loss: 0.5395 - val_accuracy: 0.7485\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8382 - val_loss: 0.5359 - val_accuracy: 0.7485\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8382 - val_loss: 0.5337 - val_accuracy: 0.7544\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8382 - val_loss: 0.5344 - val_accuracy: 0.7485\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8410 - val_loss: 0.5321 - val_accuracy: 0.7544\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8410 - val_loss: 0.5290 - val_accuracy: 0.7602\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8439 - val_loss: 0.5266 - val_accuracy: 0.7661\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8439 - val_loss: 0.5287 - val_accuracy: 0.7661\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8410 - val_loss: 0.5250 - val_accuracy: 0.7661\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8439 - val_loss: 0.5259 - val_accuracy: 0.7661\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8410 - val_loss: 0.5220 - val_accuracy: 0.7602\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.8410 - val_loss: 0.5209 - val_accuracy: 0.7719\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8382 - val_loss: 0.5194 - val_accuracy: 0.7719\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8468 - val_loss: 0.5148 - val_accuracy: 0.7778\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8497 - val_loss: 0.5161 - val_accuracy: 0.7778\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8497 - val_loss: 0.5155 - val_accuracy: 0.7778\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8526 - val_loss: 0.5126 - val_accuracy: 0.7778\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8497 - val_loss: 0.5140 - val_accuracy: 0.7778\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8526 - val_loss: 0.5111 - val_accuracy: 0.7778\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8555 - val_loss: 0.5108 - val_accuracy: 0.7778\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8555 - val_loss: 0.5106 - val_accuracy: 0.7778\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8584 - val_loss: 0.5075 - val_accuracy: 0.7778\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8555 - val_loss: 0.5067 - val_accuracy: 0.7778\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8555 - val_loss: 0.5065 - val_accuracy: 0.7778\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8613 - val_loss: 0.5047 - val_accuracy: 0.7778\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8555 - val_loss: 0.5037 - val_accuracy: 0.7778\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8613 - val_loss: 0.5013 - val_accuracy: 0.7778\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8671 - val_loss: 0.5012 - val_accuracy: 0.7895\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8613 - val_loss: 0.5001 - val_accuracy: 0.7836\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3603 - accuracy: 0.8642 - val_loss: 0.4966 - val_accuracy: 0.7953\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8671 - val_loss: 0.4962 - val_accuracy: 0.7953\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8671 - val_loss: 0.4930 - val_accuracy: 0.7953\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8613 - val_loss: 0.4936 - val_accuracy: 0.7953\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8642 - val_loss: 0.4920 - val_accuracy: 0.7953\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8613 - val_loss: 0.4914 - val_accuracy: 0.7953\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3534 - accuracy: 0.8699 - val_loss: 0.4898 - val_accuracy: 0.7953\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3520 - accuracy: 0.8642 - val_loss: 0.4901 - val_accuracy: 0.7953\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8642 - val_loss: 0.4890 - val_accuracy: 0.7953\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8699 - val_loss: 0.4874 - val_accuracy: 0.7953\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.8699 - val_loss: 0.4850 - val_accuracy: 0.7895\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3481 - accuracy: 0.8699 - val_loss: 0.4844 - val_accuracy: 0.7895\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3470 - accuracy: 0.8699 - val_loss: 0.4838 - val_accuracy: 0.7895\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3469 - accuracy: 0.8699 - val_loss: 0.4820 - val_accuracy: 0.7953\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3458 - accuracy: 0.8699 - val_loss: 0.4826 - val_accuracy: 0.7895\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8757 - val_loss: 0.4803 - val_accuracy: 0.7953\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3446 - accuracy: 0.8699 - val_loss: 0.4798 - val_accuracy: 0.8012\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3425 - accuracy: 0.8728 - val_loss: 0.4765 - val_accuracy: 0.8070\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3424 - accuracy: 0.8728 - val_loss: 0.4767 - val_accuracy: 0.8070\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3407 - accuracy: 0.8699 - val_loss: 0.4759 - val_accuracy: 0.8070\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8699 - val_loss: 0.4746 - val_accuracy: 0.8070\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3393 - accuracy: 0.8699 - val_loss: 0.4739 - val_accuracy: 0.8070\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.8728 - val_loss: 0.4735 - val_accuracy: 0.8129\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3381 - accuracy: 0.8699 - val_loss: 0.4740 - val_accuracy: 0.8129\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3387 - accuracy: 0.8757 - val_loss: 0.4705 - val_accuracy: 0.8070\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8699 - val_loss: 0.4719 - val_accuracy: 0.8129\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8728 - val_loss: 0.4702 - val_accuracy: 0.8129\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8728 - val_loss: 0.4701 - val_accuracy: 0.8129\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8699 - val_loss: 0.4680 - val_accuracy: 0.8129\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8728 - val_loss: 0.4687 - val_accuracy: 0.8129\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8757 - val_loss: 0.4672 - val_accuracy: 0.8012\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8728 - val_loss: 0.4671 - val_accuracy: 0.8070\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8728 - val_loss: 0.4652 - val_accuracy: 0.8012\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8699 - val_loss: 0.4645 - val_accuracy: 0.8012\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3298 - accuracy: 0.8728 - val_loss: 0.4641 - val_accuracy: 0.8070\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8699 - val_loss: 0.4635 - val_accuracy: 0.8070\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8699 - val_loss: 0.4635 - val_accuracy: 0.8129\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8671 - val_loss: 0.4630 - val_accuracy: 0.8070\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8699 - val_loss: 0.4623 - val_accuracy: 0.8070\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8728 - val_loss: 0.4619 - val_accuracy: 0.8070\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3254 - accuracy: 0.8757 - val_loss: 0.4600 - val_accuracy: 0.8012\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8671 - val_loss: 0.4596 - val_accuracy: 0.8012\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8699 - val_loss: 0.4603 - val_accuracy: 0.8012\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3245 - accuracy: 0.8728 - val_loss: 0.4598 - val_accuracy: 0.8012\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.8699 - val_loss: 0.4581 - val_accuracy: 0.8012\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8728 - val_loss: 0.4589 - val_accuracy: 0.8012\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8728 - val_loss: 0.4575 - val_accuracy: 0.8012\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3216 - accuracy: 0.8699 - val_loss: 0.4575 - val_accuracy: 0.8012\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3218 - accuracy: 0.8699 - val_loss: 0.4568 - val_accuracy: 0.8070\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3213 - accuracy: 0.8699 - val_loss: 0.4556 - val_accuracy: 0.8070\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8699 - val_loss: 0.4565 - val_accuracy: 0.8070\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3202 - accuracy: 0.8671 - val_loss: 0.4556 - val_accuracy: 0.8070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c00b6003a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_2.fit(X_array, y_array, validation_split=0.33, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8491\n",
      "accuracy: 84.91%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the model\n",
    "scores_2=model_2.evaluate(X_array,y_array)\n",
    "print(\"%s: %.2f%%\" % (model_2.metrics_names[1], scores_2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hence we can conclude that the first model(Base_model) where the accuracy of the model 94.97% is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
